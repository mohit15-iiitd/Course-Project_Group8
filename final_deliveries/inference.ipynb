{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from transformers import DistilBertTokenizer, DistilBertModel, BertTokenizer, BertModel\n",
    "from sklearn.metrics import classification_report\n",
    "import torchvision.transforms.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.utils import class_weight\n",
    "from torchviz import make_dot\n",
    "import torch.nn.functional as Func\n",
    "from nltk.stem import PorterStemmer\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import itertools\n",
    "import shutil\n",
    "import string\n",
    "import pickle\n",
    "import torch\n",
    "import nltk\n",
    "import json\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepressionClassifier(nn.Module):\n",
    "    def __init__(self, num_epochs, train_loader, val_loader, num_classes=2, dropout = 0.5):\n",
    "      super(DepressionClassifier, self).__init__()\n",
    "      self.num_classes = num_classes\n",
    "      self.dropout = dropout\n",
    "      self.num_epochs = num_epochs\n",
    "      \n",
    "      # Image model\n",
    "      self.image_model = models.resnet50(pretrained = True).to(device)\n",
    "      self.image_model.fc = nn.Linear(self.image_model.fc.in_features, 512)\n",
    "      \n",
    "      # Text model\n",
    "      self.text_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "      self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "      \n",
    "      # Classifier\n",
    "      self.classifier = nn.Sequential(\n",
    "          nn.Linear(512 + 768, 256),\n",
    "          \n",
    "          nn.ReLU(),\n",
    "          nn.Dropout(dropout),\n",
    "          nn.Linear(256, self.num_classes)\n",
    "      )\n",
    "      self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "      # data loaders\n",
    "      self.train_loader = train_loader\n",
    "      self.val_loader = val_loader\n",
    "\n",
    "      # loss and accuracy lists\n",
    "      self.train_loss, self.train_accuracy = [], []\n",
    "      self.val_loss, self.val_accuracy = [], []\n",
    "\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self, images, texts):\n",
    "      images = images.to(device)\n",
    "      image_features = self.image_model(images)\n",
    "\n",
    "      text_input_ids = self.tokenizer(texts, padding=True, truncation=True, return_tensors='pt').input_ids\n",
    "      text_input_ids = text_input_ids.to(device)\n",
    "\n",
    "      text_features = self.text_model(input_ids=text_input_ids).last_hidden_state[:, 0, :]\n",
    "      features = torch.cat([image_features, text_features], dim=1)\n",
    "      outputs = self.classifier(features)\n",
    "      return outputs\n",
    "\n",
    "\n",
    "    # predict method\n",
    "    def predict(self, image, text):\n",
    "      image = torch.reshape(image, (1, 3, 224, 224))\n",
    "      output = self(image, text)\n",
    "      print(output)\n",
    "      predicted_class = torch.softmax(output, dim=1).argmax(dim=1)\n",
    "      return predicted_class\n",
    "\n",
    "\n",
    "    def train_model(self, optimizer):\n",
    "      n_total_steps = len(self.train_loader)\n",
    "\n",
    "      for epoch in range(self.num_epochs):\n",
    "        # training section\n",
    "        self.train()\n",
    "        running_loss, n_correct, n_samples = 0.0, 0, 0\n",
    "\n",
    "        for index, (images, texts, labels) in enumerate(self.train_loader):\n",
    "          # Forward pass\n",
    "          images = images.to(device)\n",
    "          labels = labels.to(device)\n",
    "\n",
    "          outputs = self(images, texts)\n",
    "          loss = self.criterion(outputs, labels)\n",
    "\n",
    "          # Backward and optimize\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          running_loss += loss.item()\n",
    "          _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "          n_samples += labels.size(0)\n",
    "          n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "          if (index+1) % 266 == 0:\n",
    "            print(f'Epoch --> [{epoch+1}/{num_epochs}] | Step --> [{index+1}/{n_total_steps}] | Loss --> {loss.item():.4f} | Accuracy --> {n_correct/n_samples:.4f}')\n",
    "\n",
    "        training_loss = running_loss/n_total_steps\n",
    "        accuracy = 100.0 * n_correct / n_samples\n",
    "\n",
    "        self.train_loss.append(round(training_loss, 4))\n",
    "        self.train_accuracy.append(accuracy)\n",
    "\n",
    "        # validation section, as we have activated the model in the evaluation mode using .eval()\n",
    "        self.eval()\n",
    "        running_val_loss = 0.0\n",
    "        n_correct, n_samples = 0.0, 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "          for batch_index, (images, texts, labels) in enumerate(self.val_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = self(images, texts)\n",
    "            val_loss = self.criterion(outputs, labels)\n",
    "\n",
    "            running_val_loss += val_loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "          avg_val_loss = running_val_loss / len(self.val_loader)\n",
    "          accuracy = 100.0 * n_correct / n_samples\n",
    "\n",
    "          self.val_loss.append(avg_val_loss)\n",
    "          self.val_accuracy.append(accuracy)\n",
    "\n",
    "      print(f\"\\nValidation Accuracy of the Network: {sum(self.val_accuracy)/self.num_epochs} %\\n\")\n",
    "      print(\"Training Complete !!\")\n",
    "      return True\n",
    "\n",
    "\n",
    "    def test_model(self, loader):\n",
    "      # test_loss, test_accuracy = [], []\n",
    "      predicted_labels, actual_labels = [], []\n",
    "\n",
    "      self.eval()\n",
    "      running_test_loss = 0.0\n",
    "      n_correct, n_samples = 0.0, 0.0\n",
    "\n",
    "      with torch.no_grad():\n",
    "        for batch_index, (images, texts, labels) in enumerate(loader):\n",
    "          images = images.to(device)\n",
    "          labels = labels.to(device)\n",
    "\n",
    "          outputs = self(images, texts)\n",
    "          temp_test_loss = self.criterion(outputs, labels)\n",
    "\n",
    "          running_test_loss += temp_test_loss.item()\n",
    "\n",
    "          _, predicted = torch.max(outputs, 1)\n",
    "          n_samples += labels.size(0)\n",
    "          n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "          predicted_labels.append(list(predicted))\n",
    "          actual_labels.append(list(labels))\n",
    "\n",
    "      avg_test_loss = running_test_loss / len(loader)\n",
    "      accuracy = 100.0 * n_correct / n_samples\n",
    "\n",
    "      # test_loss.append(avg_test_loss)\n",
    "      # test_accuracy.append(accuracy)\n",
    "      predicted_labels = list(itertools.chain(*predicted_labels))\n",
    "      actual_labels = list(itertools.chain(*actual_labels))\n",
    "\n",
    "      self.train()\n",
    "      print(f\"Test Accuracy of the Network: {accuracy} %\\n\")\n",
    "      return predicted_labels, actual_labels\n",
    "      \n",
    "\n",
    "    # utility method for plotting loss and epochs\n",
    "    def plot_loss_vs_epoch(self):\n",
    "        plt.figure()\n",
    "        plt.plot(range(self.num_epochs), self.val_loss, 'b', label = 'Validation Loss')\n",
    "        plt.plot(range(self.num_epochs), self.train_loss, 'r', label = 'Training Loss')\n",
    "        plt.xlabel(\"Number of Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"EPOCH VS LOSS PLOT\")\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    # utility method for plotting accuracies and epochs\n",
    "    def plot_accuracy_vs_epoch(self):\n",
    "        plt.figure()\n",
    "        plt.plot(range(self.num_epochs), self.val_accuracy, 'b', label = 'Validation Accuracy')\n",
    "        plt.plot(range(self.num_epochs), self.train_accuracy, 'r', label = 'Training Accuracy')\n",
    "        plt.xlabel(\"Number of Epochs\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.title(\"EPOCH VS ACCURACY PLOT\")\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('/content/ir_project_model_1.pth').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = images[3]\n",
    "sample_text = texts[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(sample_image, sample_text)\n",
    "actual_label = labels[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Prediction: {prediction}\")\n",
    "print(f\"Actual: {actual_label}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
